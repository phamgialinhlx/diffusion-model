_target_: src.models.diffusion_module.DiffusionModule

defaults:
  - autoencoderconfig: autoencoder_kl_64x8x8.yaml
  - sampler: ddpm.yaml

autoencoder:
  _target_: src.models.autoencoder_module.Autoencoder

  loss: 
    _target_: src.models.modules.losses.contperceptual.LPIPSWithDiscriminator
    disc_start: 50001
    kl_weight: 0.000001
    disc_weight: 0.5
    disc_in_channels: ${data.image_channels}

  autoencoderconfig: ${model.autoencoderconfig}

  # set embed_dim equal to z_channels of autoencoderconfig
  embed_dim: ${model.autoencoderconfig.z_channels}
  lr: 4.5e-6
  ckpt_path: !!null
  colorize_nlabels: !!null
  monitor: !!null

autoencoder_ckpt_path: "/work/hpc/pgl/lung-diffusion/outputs/2023-08-17_02-31-00/checkpoints/last.ckpt" # kl64x8x8
# autoencoder_ckpt_path: "/work/hpc/pgl/lung-diffusion/outputs/2023-08-29_09-58-11/checkpoints/last.ckpt" # kl16x16x16

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.00005

scheduler: !!null
  # _target_: src.utils.lr_scheduler.LambdaWarmUpScheduler3
  # warm_up_steps: 5000

use_ema: true

net:
  _target_: src.models.diffusion.unet.UNetModel
  image_size: ${model.autoencoderconfig.out_img_size}
  in_channels: ${model.autoencoderconfig.out_channels}
  out_channels: ${model.autoencoderconfig.out_channels}
  model_channels: 192
  channel_mult: [1, 2, 4]
  attention_resolutions: [1, 2, 4, 8]
  num_heads: 8
  num_res_blocks: 2
