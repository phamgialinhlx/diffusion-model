{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae_f16_mnist = \"/mnt/work/Code/lung-diffusion/outputs/vqmodel_f16_mnist/checkpoints/last.ckpt\"\n",
    "vqvae_f16_mnist = \"/mnt/work/Code/lung-diffusion/logs/train_autoencoder/runs/2023-12-01_17-08-12/checkpoints/last.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/work/Code/lung-diffusion\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/work/Code/lung-diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.vqvae_module import VQVAE\n",
    "from src.models.klvae_module import KLVAE\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encoder.conv_in.weight', 'encoder.conv_in.bias', 'encoder.down.0.block.0.norm1.norm.weight', 'encoder.down.0.block.0.norm1.norm.bias', 'encoder.down.0.block.0.conv1.weight', 'encoder.down.0.block.0.conv1.bias', 'encoder.down.0.block.0.norm2.norm.weight', 'encoder.down.0.block.0.norm2.norm.bias', 'encoder.down.0.block.0.conv2.weight', 'encoder.down.0.block.0.conv2.bias', 'encoder.down.0.block.1.norm1.norm.weight', 'encoder.down.0.block.1.norm1.norm.bias', 'encoder.down.0.block.1.conv1.weight', 'encoder.down.0.block.1.conv1.bias', 'encoder.down.0.block.1.norm2.norm.weight', 'encoder.down.0.block.1.norm2.norm.bias', 'encoder.down.0.block.1.conv2.weight', 'encoder.down.0.block.1.conv2.bias', 'encoder.down.0.downsample.conv.weight', 'encoder.down.0.downsample.conv.bias', 'encoder.down.1.block.0.norm1.norm.weight', 'encoder.down.1.block.0.norm1.norm.bias', 'encoder.down.1.block.0.conv1.weight', 'encoder.down.1.block.0.conv1.bias', 'encoder.down.1.block.0.norm2.norm.weight', 'encoder.down.1.block.0.norm2.norm.bias', 'encoder.down.1.block.0.conv2.weight', 'encoder.down.1.block.0.conv2.bias', 'encoder.down.1.block.0.nin_shortcut.weight', 'encoder.down.1.block.0.nin_shortcut.bias', 'encoder.down.1.block.1.norm1.norm.weight', 'encoder.down.1.block.1.norm1.norm.bias', 'encoder.down.1.block.1.conv1.weight', 'encoder.down.1.block.1.conv1.bias', 'encoder.down.1.block.1.norm2.norm.weight', 'encoder.down.1.block.1.norm2.norm.bias', 'encoder.down.1.block.1.conv2.weight', 'encoder.down.1.block.1.conv2.bias', 'encoder.down.1.attn.0.norm.norm.weight', 'encoder.down.1.attn.0.norm.norm.bias', 'encoder.down.1.attn.0.q.weight', 'encoder.down.1.attn.0.q.bias', 'encoder.down.1.attn.0.k.weight', 'encoder.down.1.attn.0.k.bias', 'encoder.down.1.attn.0.v.weight', 'encoder.down.1.attn.0.v.bias', 'encoder.down.1.attn.0.proj_out.weight', 'encoder.down.1.attn.0.proj_out.bias', 'encoder.down.1.attn.1.norm.norm.weight', 'encoder.down.1.attn.1.norm.norm.bias', 'encoder.down.1.attn.1.q.weight', 'encoder.down.1.attn.1.q.bias', 'encoder.down.1.attn.1.k.weight', 'encoder.down.1.attn.1.k.bias', 'encoder.down.1.attn.1.v.weight', 'encoder.down.1.attn.1.v.bias', 'encoder.down.1.attn.1.proj_out.weight', 'encoder.down.1.attn.1.proj_out.bias', 'encoder.mid.block_1.norm1.norm.weight', 'encoder.mid.block_1.norm1.norm.bias', 'encoder.mid.block_1.conv1.weight', 'encoder.mid.block_1.conv1.bias', 'encoder.mid.block_1.norm2.norm.weight', 'encoder.mid.block_1.norm2.norm.bias', 'encoder.mid.block_1.conv2.weight', 'encoder.mid.block_1.conv2.bias', 'encoder.mid.attn_1.norm.norm.weight', 'encoder.mid.attn_1.norm.norm.bias', 'encoder.mid.attn_1.q.weight', 'encoder.mid.attn_1.q.bias', 'encoder.mid.attn_1.k.weight', 'encoder.mid.attn_1.k.bias', 'encoder.mid.attn_1.v.weight', 'encoder.mid.attn_1.v.bias', 'encoder.mid.attn_1.proj_out.weight', 'encoder.mid.attn_1.proj_out.bias', 'encoder.mid.block_2.norm1.norm.weight', 'encoder.mid.block_2.norm1.norm.bias', 'encoder.mid.block_2.conv1.weight', 'encoder.mid.block_2.conv1.bias', 'encoder.mid.block_2.norm2.norm.weight', 'encoder.mid.block_2.norm2.norm.bias', 'encoder.mid.block_2.conv2.weight', 'encoder.mid.block_2.conv2.bias', 'encoder.norm_out.norm.weight', 'encoder.norm_out.norm.bias', 'encoder.conv_out.weight', 'encoder.conv_out.bias', 'decoder.conv_in.weight', 'decoder.conv_in.bias', 'decoder.mid.block_1.norm1.norm.weight', 'decoder.mid.block_1.norm1.norm.bias', 'decoder.mid.block_1.conv1.weight', 'decoder.mid.block_1.conv1.bias', 'decoder.mid.block_1.norm2.norm.weight', 'decoder.mid.block_1.norm2.norm.bias', 'decoder.mid.block_1.conv2.weight', 'decoder.mid.block_1.conv2.bias', 'decoder.mid.attn_1.norm.norm.weight', 'decoder.mid.attn_1.norm.norm.bias', 'decoder.mid.attn_1.q.weight', 'decoder.mid.attn_1.q.bias', 'decoder.mid.attn_1.k.weight', 'decoder.mid.attn_1.k.bias', 'decoder.mid.attn_1.v.weight', 'decoder.mid.attn_1.v.bias', 'decoder.mid.attn_1.proj_out.weight', 'decoder.mid.attn_1.proj_out.bias', 'decoder.mid.block_2.norm1.norm.weight', 'decoder.mid.block_2.norm1.norm.bias', 'decoder.mid.block_2.conv1.weight', 'decoder.mid.block_2.conv1.bias', 'decoder.mid.block_2.norm2.norm.weight', 'decoder.mid.block_2.norm2.norm.bias', 'decoder.mid.block_2.conv2.weight', 'decoder.mid.block_2.conv2.bias', 'decoder.up.0.block.0.norm1.norm.weight', 'decoder.up.0.block.0.norm1.norm.bias', 'decoder.up.0.block.0.conv1.weight', 'decoder.up.0.block.0.conv1.bias', 'decoder.up.0.block.0.norm2.norm.weight', 'decoder.up.0.block.0.norm2.norm.bias', 'decoder.up.0.block.0.conv2.weight', 'decoder.up.0.block.0.conv2.bias', 'decoder.up.0.block.0.nin_shortcut.weight', 'decoder.up.0.block.0.nin_shortcut.bias', 'decoder.up.0.block.1.norm1.norm.weight', 'decoder.up.0.block.1.norm1.norm.bias', 'decoder.up.0.block.1.conv1.weight', 'decoder.up.0.block.1.conv1.bias', 'decoder.up.0.block.1.norm2.norm.weight', 'decoder.up.0.block.1.norm2.norm.bias', 'decoder.up.0.block.1.conv2.weight', 'decoder.up.0.block.1.conv2.bias', 'decoder.up.0.block.2.norm1.norm.weight', 'decoder.up.0.block.2.norm1.norm.bias', 'decoder.up.0.block.2.conv1.weight', 'decoder.up.0.block.2.conv1.bias', 'decoder.up.0.block.2.norm2.norm.weight', 'decoder.up.0.block.2.norm2.norm.bias', 'decoder.up.0.block.2.conv2.weight', 'decoder.up.0.block.2.conv2.bias', 'decoder.up.1.block.0.norm1.norm.weight', 'decoder.up.1.block.0.norm1.norm.bias', 'decoder.up.1.block.0.conv1.weight', 'decoder.up.1.block.0.conv1.bias', 'decoder.up.1.block.0.norm2.norm.weight', 'decoder.up.1.block.0.norm2.norm.bias', 'decoder.up.1.block.0.conv2.weight', 'decoder.up.1.block.0.conv2.bias', 'decoder.up.1.block.1.norm1.norm.weight', 'decoder.up.1.block.1.norm1.norm.bias', 'decoder.up.1.block.1.conv1.weight', 'decoder.up.1.block.1.conv1.bias', 'decoder.up.1.block.1.norm2.norm.weight', 'decoder.up.1.block.1.norm2.norm.bias', 'decoder.up.1.block.1.conv2.weight', 'decoder.up.1.block.1.conv2.bias', 'decoder.up.1.block.2.norm1.norm.weight', 'decoder.up.1.block.2.norm1.norm.bias', 'decoder.up.1.block.2.conv1.weight', 'decoder.up.1.block.2.conv1.bias', 'decoder.up.1.block.2.norm2.norm.weight', 'decoder.up.1.block.2.norm2.norm.bias', 'decoder.up.1.block.2.conv2.weight', 'decoder.up.1.block.2.conv2.bias', 'decoder.up.1.attn.0.norm.norm.weight', 'decoder.up.1.attn.0.norm.norm.bias', 'decoder.up.1.attn.0.q.weight', 'decoder.up.1.attn.0.q.bias', 'decoder.up.1.attn.0.k.weight', 'decoder.up.1.attn.0.k.bias', 'decoder.up.1.attn.0.v.weight', 'decoder.up.1.attn.0.v.bias', 'decoder.up.1.attn.0.proj_out.weight', 'decoder.up.1.attn.0.proj_out.bias', 'decoder.up.1.attn.1.norm.norm.weight', 'decoder.up.1.attn.1.norm.norm.bias', 'decoder.up.1.attn.1.q.weight', 'decoder.up.1.attn.1.q.bias', 'decoder.up.1.attn.1.k.weight', 'decoder.up.1.attn.1.k.bias', 'decoder.up.1.attn.1.v.weight', 'decoder.up.1.attn.1.v.bias', 'decoder.up.1.attn.1.proj_out.weight', 'decoder.up.1.attn.1.proj_out.bias', 'decoder.up.1.attn.2.norm.norm.weight', 'decoder.up.1.attn.2.norm.norm.bias', 'decoder.up.1.attn.2.q.weight', 'decoder.up.1.attn.2.q.bias', 'decoder.up.1.attn.2.k.weight', 'decoder.up.1.attn.2.k.bias', 'decoder.up.1.attn.2.v.weight', 'decoder.up.1.attn.2.v.bias', 'decoder.up.1.attn.2.proj_out.weight', 'decoder.up.1.attn.2.proj_out.bias', 'decoder.up.1.upsample.conv.weight', 'decoder.up.1.upsample.conv.bias', 'decoder.norm_out.norm.weight', 'decoder.norm_out.norm.bias', 'decoder.conv_out.weight', 'decoder.conv_out.bias', 'loss.perceptual_loss.scaling_layer.shift', 'loss.perceptual_loss.scaling_layer.scale', 'loss.perceptual_loss.net.slice1.0.weight', 'loss.perceptual_loss.net.slice1.0.bias', 'loss.perceptual_loss.net.slice1.2.weight', 'loss.perceptual_loss.net.slice1.2.bias', 'loss.perceptual_loss.net.slice2.5.weight', 'loss.perceptual_loss.net.slice2.5.bias', 'loss.perceptual_loss.net.slice2.7.weight', 'loss.perceptual_loss.net.slice2.7.bias', 'loss.perceptual_loss.net.slice3.10.weight', 'loss.perceptual_loss.net.slice3.10.bias', 'loss.perceptual_loss.net.slice3.12.weight', 'loss.perceptual_loss.net.slice3.12.bias', 'loss.perceptual_loss.net.slice3.14.weight', 'loss.perceptual_loss.net.slice3.14.bias', 'loss.perceptual_loss.net.slice4.17.weight', 'loss.perceptual_loss.net.slice4.17.bias', 'loss.perceptual_loss.net.slice4.19.weight', 'loss.perceptual_loss.net.slice4.19.bias', 'loss.perceptual_loss.net.slice4.21.weight', 'loss.perceptual_loss.net.slice4.21.bias', 'loss.perceptual_loss.net.slice5.24.weight', 'loss.perceptual_loss.net.slice5.24.bias', 'loss.perceptual_loss.net.slice5.26.weight', 'loss.perceptual_loss.net.slice5.26.bias', 'loss.perceptual_loss.net.slice5.28.weight', 'loss.perceptual_loss.net.slice5.28.bias', 'loss.perceptual_loss.lin0.model.1.weight', 'loss.perceptual_loss.lin1.model.1.weight', 'loss.perceptual_loss.lin2.model.1.weight', 'loss.perceptual_loss.lin3.model.1.weight', 'loss.perceptual_loss.lin4.model.1.weight', 'loss.perceptual_loss.lins.0.model.1.weight', 'loss.perceptual_loss.lins.1.model.1.weight', 'loss.perceptual_loss.lins.2.model.1.weight', 'loss.perceptual_loss.lins.3.model.1.weight', 'loss.perceptual_loss.lins.4.model.1.weight', 'loss.discriminator.main.0.weight', 'loss.discriminator.main.0.bias', 'loss.discriminator.main.2.weight', 'loss.discriminator.main.3.weight', 'loss.discriminator.main.3.bias', 'loss.discriminator.main.3.running_mean', 'loss.discriminator.main.3.running_var', 'loss.discriminator.main.3.num_batches_tracked', 'loss.discriminator.main.5.weight', 'loss.discriminator.main.6.weight', 'loss.discriminator.main.6.bias', 'loss.discriminator.main.6.running_mean', 'loss.discriminator.main.6.running_var', 'loss.discriminator.main.6.num_batches_tracked', 'loss.discriminator.main.8.weight', 'loss.discriminator.main.8.bias', 'quantize.embedding.weight', 'quant_conv.weight', 'quant_conv.bias', 'post_quant_conv.weight', 'post_quant_conv.bias', 'model_ema.decay', 'model_ema.num_updates', 'model_ema.encoderconv_inweight', 'model_ema.encoderconv_inbias', 'model_ema.encoderdown0block0norm1normweight', 'model_ema.encoderdown0block0norm1normbias', 'model_ema.encoderdown0block0conv1weight', 'model_ema.encoderdown0block0conv1bias', 'model_ema.encoderdown0block0norm2normweight', 'model_ema.encoderdown0block0norm2normbias', 'model_ema.encoderdown0block0conv2weight', 'model_ema.encoderdown0block0conv2bias', 'model_ema.encoderdown0block1norm1normweight', 'model_ema.encoderdown0block1norm1normbias', 'model_ema.encoderdown0block1conv1weight', 'model_ema.encoderdown0block1conv1bias', 'model_ema.encoderdown0block1norm2normweight', 'model_ema.encoderdown0block1norm2normbias', 'model_ema.encoderdown0block1conv2weight', 'model_ema.encoderdown0block1conv2bias', 'model_ema.encoderdown0downsampleconvweight', 'model_ema.encoderdown0downsampleconvbias', 'model_ema.encoderdown1block0norm1normweight', 'model_ema.encoderdown1block0norm1normbias', 'model_ema.encoderdown1block0conv1weight', 'model_ema.encoderdown1block0conv1bias', 'model_ema.encoderdown1block0norm2normweight', 'model_ema.encoderdown1block0norm2normbias', 'model_ema.encoderdown1block0conv2weight', 'model_ema.encoderdown1block0conv2bias', 'model_ema.encoderdown1block0nin_shortcutweight', 'model_ema.encoderdown1block0nin_shortcutbias', 'model_ema.encoderdown1block1norm1normweight', 'model_ema.encoderdown1block1norm1normbias', 'model_ema.encoderdown1block1conv1weight', 'model_ema.encoderdown1block1conv1bias', 'model_ema.encoderdown1block1norm2normweight', 'model_ema.encoderdown1block1norm2normbias', 'model_ema.encoderdown1block1conv2weight', 'model_ema.encoderdown1block1conv2bias', 'model_ema.encoderdown1attn0normnormweight', 'model_ema.encoderdown1attn0normnormbias', 'model_ema.encoderdown1attn0qweight', 'model_ema.encoderdown1attn0qbias', 'model_ema.encoderdown1attn0kweight', 'model_ema.encoderdown1attn0kbias', 'model_ema.encoderdown1attn0vweight', 'model_ema.encoderdown1attn0vbias', 'model_ema.encoderdown1attn0proj_outweight', 'model_ema.encoderdown1attn0proj_outbias', 'model_ema.encoderdown1attn1normnormweight', 'model_ema.encoderdown1attn1normnormbias', 'model_ema.encoderdown1attn1qweight', 'model_ema.encoderdown1attn1qbias', 'model_ema.encoderdown1attn1kweight', 'model_ema.encoderdown1attn1kbias', 'model_ema.encoderdown1attn1vweight', 'model_ema.encoderdown1attn1vbias', 'model_ema.encoderdown1attn1proj_outweight', 'model_ema.encoderdown1attn1proj_outbias', 'model_ema.encodermidblock_1norm1normweight', 'model_ema.encodermidblock_1norm1normbias', 'model_ema.encodermidblock_1conv1weight', 'model_ema.encodermidblock_1conv1bias', 'model_ema.encodermidblock_1norm2normweight', 'model_ema.encodermidblock_1norm2normbias', 'model_ema.encodermidblock_1conv2weight', 'model_ema.encodermidblock_1conv2bias', 'model_ema.encodermidattn_1normnormweight', 'model_ema.encodermidattn_1normnormbias', 'model_ema.encodermidattn_1qweight', 'model_ema.encodermidattn_1qbias', 'model_ema.encodermidattn_1kweight', 'model_ema.encodermidattn_1kbias', 'model_ema.encodermidattn_1vweight', 'model_ema.encodermidattn_1vbias', 'model_ema.encodermidattn_1proj_outweight', 'model_ema.encodermidattn_1proj_outbias', 'model_ema.encodermidblock_2norm1normweight', 'model_ema.encodermidblock_2norm1normbias', 'model_ema.encodermidblock_2conv1weight', 'model_ema.encodermidblock_2conv1bias', 'model_ema.encodermidblock_2norm2normweight', 'model_ema.encodermidblock_2norm2normbias', 'model_ema.encodermidblock_2conv2weight', 'model_ema.encodermidblock_2conv2bias', 'model_ema.encodernorm_outnormweight', 'model_ema.encodernorm_outnormbias', 'model_ema.encoderconv_outweight', 'model_ema.encoderconv_outbias', 'model_ema.decoderconv_inweight', 'model_ema.decoderconv_inbias', 'model_ema.decodermidblock_1norm1normweight', 'model_ema.decodermidblock_1norm1normbias', 'model_ema.decodermidblock_1conv1weight', 'model_ema.decodermidblock_1conv1bias', 'model_ema.decodermidblock_1norm2normweight', 'model_ema.decodermidblock_1norm2normbias', 'model_ema.decodermidblock_1conv2weight', 'model_ema.decodermidblock_1conv2bias', 'model_ema.decodermidattn_1normnormweight', 'model_ema.decodermidattn_1normnormbias', 'model_ema.decodermidattn_1qweight', 'model_ema.decodermidattn_1qbias', 'model_ema.decodermidattn_1kweight', 'model_ema.decodermidattn_1kbias', 'model_ema.decodermidattn_1vweight', 'model_ema.decodermidattn_1vbias', 'model_ema.decodermidattn_1proj_outweight', 'model_ema.decodermidattn_1proj_outbias', 'model_ema.decodermidblock_2norm1normweight', 'model_ema.decodermidblock_2norm1normbias', 'model_ema.decodermidblock_2conv1weight', 'model_ema.decodermidblock_2conv1bias', 'model_ema.decodermidblock_2norm2normweight', 'model_ema.decodermidblock_2norm2normbias', 'model_ema.decodermidblock_2conv2weight', 'model_ema.decodermidblock_2conv2bias', 'model_ema.decoderup0block0norm1normweight', 'model_ema.decoderup0block0norm1normbias', 'model_ema.decoderup0block0conv1weight', 'model_ema.decoderup0block0conv1bias', 'model_ema.decoderup0block0norm2normweight', 'model_ema.decoderup0block0norm2normbias', 'model_ema.decoderup0block0conv2weight', 'model_ema.decoderup0block0conv2bias', 'model_ema.decoderup0block0nin_shortcutweight', 'model_ema.decoderup0block0nin_shortcutbias', 'model_ema.decoderup0block1norm1normweight', 'model_ema.decoderup0block1norm1normbias', 'model_ema.decoderup0block1conv1weight', 'model_ema.decoderup0block1conv1bias', 'model_ema.decoderup0block1norm2normweight', 'model_ema.decoderup0block1norm2normbias', 'model_ema.decoderup0block1conv2weight', 'model_ema.decoderup0block1conv2bias', 'model_ema.decoderup0block2norm1normweight', 'model_ema.decoderup0block2norm1normbias', 'model_ema.decoderup0block2conv1weight', 'model_ema.decoderup0block2conv1bias', 'model_ema.decoderup0block2norm2normweight', 'model_ema.decoderup0block2norm2normbias', 'model_ema.decoderup0block2conv2weight', 'model_ema.decoderup0block2conv2bias', 'model_ema.decoderup1block0norm1normweight', 'model_ema.decoderup1block0norm1normbias', 'model_ema.decoderup1block0conv1weight', 'model_ema.decoderup1block0conv1bias', 'model_ema.decoderup1block0norm2normweight', 'model_ema.decoderup1block0norm2normbias', 'model_ema.decoderup1block0conv2weight', 'model_ema.decoderup1block0conv2bias', 'model_ema.decoderup1block1norm1normweight', 'model_ema.decoderup1block1norm1normbias', 'model_ema.decoderup1block1conv1weight', 'model_ema.decoderup1block1conv1bias', 'model_ema.decoderup1block1norm2normweight', 'model_ema.decoderup1block1norm2normbias', 'model_ema.decoderup1block1conv2weight', 'model_ema.decoderup1block1conv2bias', 'model_ema.decoderup1block2norm1normweight', 'model_ema.decoderup1block2norm1normbias', 'model_ema.decoderup1block2conv1weight', 'model_ema.decoderup1block2conv1bias', 'model_ema.decoderup1block2norm2normweight', 'model_ema.decoderup1block2norm2normbias', 'model_ema.decoderup1block2conv2weight', 'model_ema.decoderup1block2conv2bias', 'model_ema.decoderup1attn0normnormweight', 'model_ema.decoderup1attn0normnormbias', 'model_ema.decoderup1attn0qweight', 'model_ema.decoderup1attn0qbias', 'model_ema.decoderup1attn0kweight', 'model_ema.decoderup1attn0kbias', 'model_ema.decoderup1attn0vweight', 'model_ema.decoderup1attn0vbias', 'model_ema.decoderup1attn0proj_outweight', 'model_ema.decoderup1attn0proj_outbias', 'model_ema.decoderup1attn1normnormweight', 'model_ema.decoderup1attn1normnormbias', 'model_ema.decoderup1attn1qweight', 'model_ema.decoderup1attn1qbias', 'model_ema.decoderup1attn1kweight', 'model_ema.decoderup1attn1kbias', 'model_ema.decoderup1attn1vweight', 'model_ema.decoderup1attn1vbias', 'model_ema.decoderup1attn1proj_outweight', 'model_ema.decoderup1attn1proj_outbias', 'model_ema.decoderup1attn2normnormweight', 'model_ema.decoderup1attn2normnormbias', 'model_ema.decoderup1attn2qweight', 'model_ema.decoderup1attn2qbias', 'model_ema.decoderup1attn2kweight', 'model_ema.decoderup1attn2kbias', 'model_ema.decoderup1attn2vweight', 'model_ema.decoderup1attn2vbias', 'model_ema.decoderup1attn2proj_outweight', 'model_ema.decoderup1attn2proj_outbias', 'model_ema.decoderup1upsampleconvweight', 'model_ema.decoderup1upsampleconvbias', 'model_ema.decodernorm_outnormweight', 'model_ema.decodernorm_outnormbias', 'model_ema.decoderconv_outweight', 'model_ema.decoderconv_outbias', 'model_ema.lossperceptual_losslin0model1weight', 'model_ema.lossperceptual_losslin1model1weight', 'model_ema.lossperceptual_losslin2model1weight', 'model_ema.lossperceptual_losslin3model1weight', 'model_ema.lossperceptual_losslin4model1weight', 'model_ema.lossdiscriminatormain0weight', 'model_ema.lossdiscriminatormain0bias', 'model_ema.lossdiscriminatormain2weight', 'model_ema.lossdiscriminatormain3weight', 'model_ema.lossdiscriminatormain3bias', 'model_ema.lossdiscriminatormain5weight', 'model_ema.lossdiscriminatormain6weight', 'model_ema.lossdiscriminatormain6bias', 'model_ema.lossdiscriminatormain8weight', 'model_ema.lossdiscriminatormain8bias', 'model_ema.quantizeembeddingweight', 'model_ema.quant_convweight', 'model_ema.quant_convbias', 'model_ema.post_quant_convweight', 'model_ema.post_quant_convbias']\n"
     ]
    }
   ],
   "source": [
    "# ae = Autoencoder(vqvae_f16_mnist).eval()\n",
    "sd = torch.load(vqvae_f16_mnist, map_location=\"cpu\")[\"state_dict\"]\n",
    "keys = list(sd.keys())\n",
    "print(keys)\n",
    "# VQVAE.load_from_checkpoint(vqvae_f16_mnist).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping EMAs of 224.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ae = KLVAE.load_from_checkpoint(vqvae_f16_mnist).eval()\n",
    "except Exception as e:\n",
    "    ae = VQVAE.load_from_checkpoint(vqvae_f16_mnist).eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
